{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from transformers import AutoTokenizer\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "from io import BytesIO\n",
        "import base64\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/multimodal_dataset_with_images.csv\")\n",
        "\n",
        "TEXT_COLUMN = \"Symptoms_Description\"\n",
        "IMAGE_COLUMN = \"Image_Data_Base64\"  # Use 'Image_Data_Base64' for base64 encoded images\n",
        "\n",
        "# Initialize tokenizer for BERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenize text data\n",
        "def tokenize_text(text):\n",
        "    return tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Preprocess images from base64\n",
        "def preprocess_base64_image(base64_string):\n",
        "    image_bytes = base64.b64decode(base64_string)\n",
        "    image = Image.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    return transform(image).unsqueeze(0)\n",
        "\n",
        "# Example usage\n",
        "text_tokens = tokenize_text(df[TEXT_COLUMN].iloc[0])  # Tokenize text\n",
        "image_tensor = preprocess_base64_image(df[IMAGE_COLUMN].iloc[0])  # Preprocess base64 image\n",
        "\n",
        "print(\"Image Shape:\", image_tensor.shape, \"Text Tokens:\", text_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Lm-Yn2oFuLct",
        "outputId": "4d5c2893-f77c-4bce-9b9f-b50d7305784a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Shape: torch.Size([1, 3, 224, 224]) Text Tokens: {'input_ids': tensor([[  101,  5729, 14978,  1998,  4487, 29212,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiModalModel(nn.Module):\n",
        "    def __init__(self, text_model_name, image_feature_size, numerical_input_size, output_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # Load pre-trained text encoder (e.g., BERT)\n",
        "        self.text_encoder = AutoModel.from_pretrained(text_model_name)\n",
        "\n",
        "        # Define a simple image feature extractor\n",
        "        self.image_fc = nn.Linear(image_feature_size, 512)\n",
        "\n",
        "        # Numerical feature processing\n",
        "        self.fc_numeric = nn.Linear(numerical_input_size, 128)\n",
        "\n",
        "        # Final classifier combining all modalities\n",
        "        self.fc_combined = nn.Linear(768 + 512 + 128, output_classes)\n",
        "\n",
        "    def forward(self, text_tokens, image_features, numerical_data):\n",
        "        # Encode text using the text model\n",
        "        text_features = self.text_encoder(**text_tokens).last_hidden_state[:, 0, :]\n",
        "\n",
        "        # Process image features\n",
        "        image_features = self.image_fc(image_features)\n",
        "\n",
        "        # Process numerical data\n",
        "        numeric_features = self.fc_numeric(numerical_data)\n",
        "\n",
        "        # Concatenate all features\n",
        "        combined = torch.cat((text_features, image_features, numeric_features), dim=1)\n",
        "\n",
        "        # Pass through the final classifier\n",
        "        return self.fc_combined(combined)\n",
        "\n",
        "# Example of defining the model\n",
        "text_model_name = \"bert-base-uncased\"\n",
        "image_feature_size = 2048  # Example feature size from an image encoder like ResNet\n",
        "numerical_input_size = 3  # Number of numerical features (Heart Rate, Temperature, WBC Count)\n",
        "output_classes = 10  # Example number of output classes\n",
        "\n",
        "# Create the model instance\n",
        "model = MultiModalModel(\n",
        "    text_model_name=text_model_name,\n",
        "    image_feature_size=image_feature_size,\n",
        "    numerical_input_size=numerical_input_size,\n",
        "    output_classes=output_classes\n",
        ")\n",
        "\n",
        "print(\"Model Ready:\", model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4FcgdZ_ttn3d",
        "outputId": "c9695853-9980-4b20-8fdf-4bae4d2ba36a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Ready: MultiModalModel(\n",
            "  (text_encoder): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (image_fc): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (fc_numeric): Linear(in_features=3, out_features=128, bias=True)\n",
            "  (fc_combined): Linear(in_features=1408, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "# Save the trained model\n",
        "def save_model(model, file_name=\"multi_modal_model.pth\"):\n",
        "    torch.save(model.state_dict(), file_name)\n",
        "    print(\"Model saved successfully\")\n",
        "\n",
        "# Verify model file\n",
        "def verify_model_file(file_name=\"multi_modal_model.pth\"):\n",
        "    if os.path.exists(file_name):\n",
        "        print(\"Model file found\")\n",
        "    else:\n",
        "        print(\"Model file is missing. Train and save it again.\")\n",
        "\n",
        "# Save and verify the model\n",
        "save_model(model, \"multi_modal_model.pth\")\n",
        "verify_model_file(\"multi_modal_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiYHrFkBumXg",
        "outputId": "f9a0e4f7-40a7-4cfc-e02e-15ab44e791c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully\n",
            "Model file found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit_code = \"\"\"\n",
        "import streamlit as st\n",
        "import torch\n",
        "import base64\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from transformers import AutoTokenizer\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "\n",
        "st.title(\"Multi-Modal Prediction\")\n",
        "\n",
        "# Define numerical columns\n",
        "NUMERICAL_COLUMNS = [\"Heart_Rate_bpm\", \"Body_Temperature_F\", \"WBC_Count_10^3/uL\"]\n",
        "\n",
        "# Load trained model\n",
        "class MultiModalModel(torch.nn.Module):\n",
        "    def __init__(self, text_model_name, numerical_input_size, image_feature_size, output_classes):\n",
        "        super(MultiModalModel, self).__init__()\n",
        "        self.fc_combined = torch.nn.Linear(numerical_input_size + image_feature_size, output_classes)\n",
        "\n",
        "    def forward(self, text_tokens, image_tensor, numerical_data):\n",
        "        combined_features = torch.cat((image_tensor.view(image_tensor.size(0), -1), numerical_data), dim=1)\n",
        "        return self.fc_combined(combined_features)\n",
        "\n",
        "model = MultiModalModel(\n",
        "    text_model_name=\"bert-base-uncased\",\n",
        "    numerical_input_size=len(NUMERICAL_COLUMNS),\n",
        "    image_feature_size=2048,  # Adjusted based on model checkpoint\n",
        "    output_classes=10  # Adjusted based on model checkpoint\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"multi_modal_model.pth\", map_location=torch.device(\"cpu\")), strict=False)\n",
        "model.eval()\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Input fields\n",
        "symptoms = st.text_area(\"Enter Symptoms\")\n",
        "heart_rate = st.number_input(\"Heart Rate (bpm)\", min_value=50, max_value=200, value=80)\n",
        "temperature = st.number_input(\"Body Temperature (°F)\", min_value=90.0, max_value=110.0, value=98.6)\n",
        "wbc_count = st.number_input(\"WBC Count (10^3/uL)\", min_value=2.0, max_value=20.0, value=7.0)\n",
        "base64_image = st.text_area(\"Paste Base64 Image Data\")\n",
        "\n",
        "def decode_base64_image(base64_string):\n",
        "    try:\n",
        "        image_data = base64.b64decode(base64_string)\n",
        "        image = Image.open(BytesIO(image_data)).convert(\"RGB\")\n",
        "        return image\n",
        "    except Exception:\n",
        "        st.error(\"Invalid Base64 image data\")\n",
        "        return None\n",
        "\n",
        "if st.button(\"Predict\"):\n",
        "    if symptoms and base64_image:\n",
        "        image = decode_base64_image(base64_image)\n",
        "        if image:\n",
        "            transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "            image_tensor = transform(image).unsqueeze(0)\n",
        "\n",
        "            text_tokens = tokenizer(symptoms, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "            numerical_data = torch.tensor([[heart_rate, temperature, wbc_count]], dtype=torch.float32)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                prediction = model(text_tokens, image_tensor, numerical_data)\n",
        "\n",
        "            diagnosis = torch.argmax(prediction, dim=1).item()\n",
        "            st.success(f\"Prediction Class: {diagnosis}\")\n",
        "    else:\n",
        "        st.warning(\"Please enter symptoms and provide an image in Base64 format\")\n",
        "\"\"\"\n",
        "\n",
        "# Save the script\n",
        "with open(\"streamlit_app.py\", \"w\") as f:\n",
        "    f.write(streamlit_code)\n",
        "\n",
        "print(\"streamlit_app.py has been created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwwSjYI040AK",
        "outputId": "a0682010-936a-4667-d01a-0299b23be42c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "streamlit_app.py has been created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import torch\n",
        "import base64\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from transformers import AutoTokenizer\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "\n",
        "st.title(\"Multi-Modal Prediction\")\n",
        "\n",
        "# Define numerical columns\n",
        "NUMERICAL_COLUMNS = [\"Heart_Rate_bpm\", \"Body_Temperature_F\", \"WBC_Count_10^3/uL\"]\n",
        "\n",
        "# Load dataset for reference\n",
        "#df = pd.read_csv(\"multimodal_dataset_with_images.csv\")\n",
        "\n",
        "# Load trained model\n",
        "model = MultiModalModel(\n",
        "    text_model_name=\"bert-base-uncased\",\n",
        "    numerical_input_size=len(NUMERICAL_COLUMNS),\n",
        "    image_feature_size=2048,  # Adjusted based on model checkpoint error\n",
        "    output_classes=10  # Adjusted based on model checkpoint error\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"multi_modal_model.pth\", map_location=torch.device(\"cpu\")), strict=False)\n",
        "model.eval()\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Input fields\n",
        "symptoms = st.text_area(\"Enter Symptoms\")\n",
        "heart_rate = st.number_input(\"Heart Rate (bpm)\", min_value=50, max_value=200, value=80)\n",
        "temperature = st.number_input(\"Body Temperature (°F)\", min_value=90.0, max_value=110.0, value=98.6)\n",
        "wbc_count = st.number_input(\"WBC Count (10^3/uL)\", min_value=2.0, max_value=20.0, value=7.0)\n",
        "base64_image = st.text_area(\"Paste Base64 Image Data\")\n",
        "\n",
        "def decode_base64_image(base64_string):\n",
        "    try:\n",
        "        image_data = base64.b64decode(base64_string)\n",
        "        image = Image.open(BytesIO(image_data)).convert(\"RGB\")\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        st.error(\"Invalid Base64 image data\")\n",
        "        return None\n",
        "\n",
        "if st.button(\"Predict\"):\n",
        "    if symptoms and base64_image:\n",
        "        image = decode_base64_image(base64_image)\n",
        "        if image:\n",
        "            transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "            image_tensor = transform(image).unsqueeze(0)\n",
        "\n",
        "            text_tokens = tokenizer(symptoms, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "            numerical_data = torch.tensor([[heart_rate, temperature, wbc_count]], dtype=torch.float32)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                prediction = model(text_tokens, image_tensor, numerical_data)\n",
        "\n",
        "            diagnosis = torch.argmax(prediction, dim=1).item()\n",
        "            st.success(f\"Prediction Class: {diagnosis}\")\n",
        "    else:\n",
        "        st.warning(\"Please enter symptoms and provide an image in Base64 format\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NbKA3Qtf0GRf",
        "outputId": "f151c8c4-8149-4f9b-992a-03ba8035f3be"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-07 05:09:59.923 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:09:59.928 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "<ipython-input-11-8536b61de612>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"multi_modal_model.pth\", map_location=torch.device(\"cpu\")), strict=False)\n",
            "2025-02-07 05:10:04.041 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.145 Session state does not function when running a script without `streamlit run`\n",
            "2025-02-07 05:10:04.153 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.159 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.174 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.176 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.183 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.187 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.192 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.199 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.211 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.215 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.223 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.226 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.234 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.241 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.245 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.250 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.260 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.280 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.284 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.325 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.328 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.333 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.339 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.364 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.367 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.374 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.377 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-07 05:10:04.385 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run streamlit_app.py\n",
        ""
      ],
      "metadata": {
        "id": "NPGfebXo8Al3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}